[exporter]
# 0 for running this in current thread, > 1 to use a threadpool. (this can be verified with ps -eTwww -p <pid of exporter proxy>)
worker_threads = 0
# concurrent connections to each handler. This limit will be applied for each receiving handler (unix and tcp) via semaphores.
# Make sure the ulimit has enough openfile limit to handle the number of concurrent requests. Max allowed value is 65534
# This limit is not applied for poll_external, as it is rare to hit a threshold limit and the limit can be controlled
# by restricting the number of endpoints in `other_scrape_endpoints` under the poll_external section.
concurrent_requests = 2048
stale_check_interval = 1
stale_metric_ttl = 10
# The endpoint where prometheus can scrape the collective metrics.
scrape_expose_endpoint = "0.0.0.0:6555"
[receiver]
# Receive events in capn' proto. Comment to disable.
[receiver.capnp]
# listen for capnp events on unix socket. Comment to disable.
receiver_unix_socket = "/var/run/exporter-proxy-receiver-capnp.sock"
# unix socket user and group ownership
unix_socket_user = "root"
unix_socket_group = "root"

# listen for capnp events on tcp socket. Comment to disable.
receiver_tcp_socket = "127.0.0.1:6554"

# Receive events in json format. Comment to disable.
[receiver.json]
# listen for json events on unix socket. Comment to disable.
receiver_unix_socket = "/var/run/exporter-proxy-receiver-json.sock"
# unix socket user and group ownership
unix_socket_user = "root"
unix_socket_group = "root"

# listen for json events on tcp socket. Comment to disable.
receiver_tcp_socket = "127.0.0.1:6553"

[poll_external]
other_scrape_endpoints = ["http://127.0.0.1:1025/1025.html", "http://127.0.0.1:1026/1026.html", "http://127.0.0.1:1027/1027.html"]
allow_invalid_certs = true
poll_interval = 5 # in seconds
client_timeout = 2 # in seconds

